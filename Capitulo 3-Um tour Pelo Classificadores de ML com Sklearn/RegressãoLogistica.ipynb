{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base     import ClassifierMixin\n",
    "from sklearn.datasets import load_iris,make_classification\n",
    "from sklearn.metrics  import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logaritmo das chances : probabilidade de acontecer e não acontecer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p:np.array): \n",
    "    return np.log( p/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probalidade = np.around(np.linspace(0.1,0.9,9),2)\n",
    "print(probalidade)\n",
    "logit(probalidade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função sigmoid: é a inversa do logaritmos das chances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z:np.array):\n",
    "    return 1.0/( 1.0 + np.exp(-1*z) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z  = np.linspace(-6,6)\n",
    "zy = sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z,zy,'o-')\n",
    "plt.axvline(0,color='k')\n",
    "plt.axhline(0,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de custo|perda (log-loss)\n",
    "$$\n",
    "L(\\sigma(z),y;w,b) = -y \\cdot \\log(\\sigma(z) ) - (1-y)\\cdot \\log(1-\\sigma(z))\n",
    "$$\n",
    "\n",
    "* Se o y = 0 para uma unica instancia de treinamento a função de perda será igual a $(1-y)\\cdot \\log(1-h_{\\theta}(z))$ , a penalidade aumenta a medida que se aproxima de 1\n",
    "* Se o y = 1 para uma unica instancia de treinamento a função de perda será igual a $-\\log(h_{\\theta}(x))$ , a penalidade aumenta a medida que se aproxima de 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perda1(sigmoid): return -np.log(sigmoid)\n",
    "def perda2(sigmoid): return -np.log(1-sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoidExample = np.linspace(0.001,0.99,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmoidExample,perda1(sigmoidExample),label='-log(Ŷ)   se y = 1')\n",
    "plt.plot(sigmoidExample,perda2(sigmoidExample),label='-log(1-Ŷ) se y = 0')\n",
    "plt.axhline(0,color='k')\n",
    "plt.legend(bbox_to_anchor=(1,1,0,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame({'z':sigmoidExample,'-log(1-h(x))':perda2(sigmoidExample)}),pd.DataFrame({'z':sigmoidExample,'-log(h(x))':perda1(sigmoidExample)})],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None,encoding='utf-8')\n",
    "\n",
    "X = data.iloc[:,[1,2]].values\n",
    "y = data.iloc[:,4]\n",
    "y = np.where(y=='Iris-setosa',0,1)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, train_size=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressaoLogisticaGD(ClassifierMixin):\n",
    "    b_ = None # Vies||Bias\n",
    "    w_ = None # Pesos\n",
    "    n_ = None # Numero de caracteristicas\n",
    "\n",
    "    def __init__(self, eta=0.01, max_iter=50, random_state=1,alpha=0):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n_ = np.size(X, axis=1)\n",
    "        rgen    = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal( loc=0.0, scale=0.01, size=self.n_ )\n",
    "        self.b_ = np.float64(0.0)\n",
    "\n",
    "        self.losses_ = [] #F(x) para cada epoca\n",
    "\n",
    "        for iter in range(self.max_iter):\n",
    "            somaPonderada = self.somaPonderada(X)\n",
    "            valorPrevisto = self.activacaoSigmoid(somaPonderada)\n",
    "            erros = (y-valorPrevisto)\n",
    "\n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(erros)/np.size(X, axis=0) + (self.alpha*(self.w_))/np.size(X, axis=0)\n",
    "            self.b_ += self.eta * 2.0 * np.mean(erros)\n",
    "\n",
    "            loss = -y.dot(np.log(valorPrevisto)) - ((1-y).dot(np.log(1-valorPrevisto)))/np.size(X, axis=0) + (self.alpha*np.linalg.norm(self.w_))/np.size(X, axis=0)\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "\n",
    "    def somaPonderada(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    \n",
    "    def activacaoSigmoid(self, Z):\n",
    "        return 1./(1. + np.exp(-Z))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where( self.activacaoSigmoid(self.somaPonderada(X))>=0.5,1,0)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitic = RegressaoLogisticaGD(max_iter=100,alpha=1)\n",
    "logitic.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitic.w_,logitic.b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predL = logitic.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest,predL))\n",
    "print(accuracy_score(ytest,predL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.PlotRegiaDeDecisao import plotDecisionRegion,plotDecisionRegion2\n",
    "\n",
    "plotDecisionRegion(xtest,ytest,logitic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxGD(ClassifierMixin):\n",
    "    b_ = None # Vies||Bias\n",
    "    w_ = None # Pesos\n",
    "    n_ = None # Numero de caracteristicas\n",
    "    k_ = None\n",
    "    def __init__(self, eta=0.1, max_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y += 1\n",
    "        self.k_ = len(np.unique(y))\n",
    "\n",
    "        self.n_ = np.size(X, axis=1)\n",
    "        rgen    = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal( loc=0.0, scale=0.1, size=(self.k_,self.n_))\n",
    "        self.b_ = np.zeros(shape=(self.k_,1))\n",
    "        self.losses_ = []\n",
    "        \n",
    "        for iter in range(self.max_iter):\n",
    "           \n",
    "            erros = []\n",
    "            for ki in range(self.k_):\n",
    "                error = (np.where( y == ki+1,ki+1,0 ) - self.ativacaoSoftMax(X,ki)[0])\n",
    "                erros.append(error)\n",
    "            \n",
    "            erros = np.array(erros).T\n",
    "           \n",
    "            for ki in range(self.k_):\n",
    "                self.w_[ki,:] += self.eta * 2.0 * X.T.dot(erros[:,ki])/np.size(X, axis=0)\n",
    "                self.b_[ki,:] += self.eta * 2.0 * np.mean(erros[:,ki])\n",
    "            \n",
    "            error = 0\n",
    "            for ki in range(self.k_):\n",
    "                error += np.sum(np.log(np.where( y == ki+1,ki+1,0 )*self.ativacaoSoftMax(X,ki)[0]))\n",
    "            \n",
    "\n",
    "        return self\n",
    "\n",
    "    def somaSoftMax(self, X, ki):\n",
    "        return np.dot(X, self.w_[ki,:]) + self.b_[ki,:]\n",
    "        \n",
    "    def ativacaoSoftMax(self, X, ki):\n",
    "        n =  np.size(X, axis=0)\n",
    "        exp1 = np.around(np.exp(self.somaSoftMax(X,ki)),decimals=5)\n",
    "        exp2 = np.zeros(shape=(1,n))\n",
    "       \n",
    "        for ki in range(self.k_):\n",
    "            exp2+= np.around(np.exp(self.somaSoftMax(X,ki)),decimals=5)\n",
    "\n",
    "        \n",
    "\n",
    "        return exp1/exp2\n",
    "\n",
    "    def predict(self, X):\n",
    "        soft = []\n",
    "        for ki in range(self.k_):\n",
    "            soft.append(self.ativacaoSoftMax(X,ki)[0])\n",
    "        soft = np.array(soft).T\n",
    "        return np.array([np.argmax(xi)for xi in soft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X = X[:,[2,3]]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=0,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "xtrain = StandardScaler().fit_transform(xtrain)\n",
    "xtest  = StandardScaler().fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = SoftMaxGD(eta=0.01,max_iter=1000,random_state=1)\n",
    "soft.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = soft.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest+1,pred+1))\n",
    "print(accuracy_score(ytest+1,pred+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytest+1,pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.PlotRegiaDeDecisao import plotDecisionRegion,plotDecisionRegion2\n",
    "\n",
    "plotDecisionRegion2(xtest,ytest,soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistica OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressaoLogisticaOvr(ClassifierMixin):\n",
    "    def __init__(self, max_iter=100, random_state=None):\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.listEstimator = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        labels = np.unique(y)\n",
    "        self.listEstimator = {}\n",
    "        for classi in labels:\n",
    "            y_bin = np.where(y == classi, 1, 0)\n",
    "            estimator = RegressaoLogisticaGD(max_iter=self.max_iter, random_state=self.random_state)\n",
    "            estimator.fit(X, y_bin)\n",
    "            self.listEstimator[classi] = estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.listEstimator is None:\n",
    "            raise TypeError('None')\n",
    "        \n",
    "        pred = []\n",
    "        for xi in X:\n",
    "            class_scores = {}\n",
    "            for key, estimator in self.listEstimator.items():\n",
    "                class_scores[key] = estimator.predict(xi.reshape(1, -1)).item()\n",
    "            pred.append(max(class_scores, key=class_scores.get))\n",
    "        return np.array(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X = X[:,[0,1]]\n",
    "X = ().fit_transform(X)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RegressaoLogisticaOvr(max_iter=1000,random_state=10)\n",
    "reg.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(xtest)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.listEstimator[0].w_,reg.listEstimator[1].w_,reg.listEstimator[2].w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest,pred))\n",
    "print(accuracy_score(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDecisionRegion2(xtest,ytest,reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonVirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
